{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (1.64.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhaskaradhikari\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.64.0\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "print(openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Instantiate the client with your API key from environment variables\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def get_chat_completion(prompt, model=\"gpt-4\"):\n",
    "    try:\n",
    "        # Create a chat completion request\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=model\n",
    "        )\n",
    "        \n",
    "        # Extract the text from the response\n",
    "        # Assuming 'choices' is correctly accessed, get the text content from message\n",
    "        completion_message = response.choices[0].message\n",
    "        return completion_message.content.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "result = get_chat_completion(\"Say this is a test\")\n",
    "if result:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Tale of Brave Sir Edmund\n",
      "\n",
      "Once upon a time, in a realm steeped in magic and mystery, there existed a noble knight by the name of Sir Edmund. Known for his bravery and unwavering loyalty to his king, Sir Edmund was a paragon of knightly virtues and the embodiment of courage.\n",
      "\n",
      "One fateful day, as the sun disappeared beyond the horizon, a dark beast arose from the deepest abyss of the northern mountains. The titanic serpent, known as Melthos, breathed fire and spewed smoke, casting a deadly shadow over the kingdom of Veridia. Panic ensued as the beast's terror swept across the land, leaving desolation in its wake.\n",
      "\n",
      "Edmund, hearing news of the calamity, rushed"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Instantiate the OpenAI client with your API key\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def stream_chat_response(prompt, model=\"gpt-4\"):\n",
    "    try:\n",
    "        # Create a streaming completion request\n",
    "        response_stream = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            stream=True,  # Enable streaming mode\n",
    "            max_tokens = 150,\n",
    "            temperature = 0.9 # Controls the level of creativity (0 to 1)\n",
    "        )\n",
    "        \n",
    "        # Iterate over the stream response\n",
    "        for chunk in response_stream:\n",
    "            # Print each chunk's content immediately as it's received\n",
    "            if chunk.choices[0].delta.content:\n",
    "                print(chunk.choices[0].delta.content, end='')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "stream_chat_response(\"Can you tell me a story about a brave knight?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3The word \"communication\" has 13 characters.Could you please specify the word you are referring to?\"Communication\" is the process of exchanging information, ideas, thoughts, or feelings between individuals or groups through spoken, written, or non-verbal methods. Effective communication involves a sender conveying a message and a receiver interpreting it accurately. It is essential for building relationships, collaborating, and understanding one another in personal and professional contexts. Various forms of communication include verbal, non-verbal (such as body language or facial expressions), written (like emails or texts), and visual (such as images or videos)."
     ]
    }
   ],
   "source": [
    "# Instantiate the OpenAI client with your API key\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Initialize the conversation history\n",
    "conversation_history = []\n",
    "\n",
    "def stream_chat_response(user_input, model=\"gpt-4o\"):\n",
    "    try:\n",
    "        # Create a streaming completion request\n",
    "        response_stream = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": user_input}],\n",
    "            stream=True,  # Enable streaming mode\n",
    "            max_tokens=150,\n",
    "            temperature=0.9  # Controls the level of creativity (0 to 1)\n",
    "        )\n",
    "\n",
    "        bot_response = \"\"\n",
    "\n",
    "        # Iterate over the streaming response chunks\n",
    "        for chunk in response_stream:\n",
    "            # Check if a content part was received in this chunk\n",
    "            if chunk.choices[0].delta.content:\n",
    "                # Accumulate the content parts into bot_response\n",
    "                bot_response += chunk.choices[0].delta.content\n",
    "                # Print each chunk content promptly as it arrives\n",
    "                print(chunk.choices[0].delta.content, end='')\n",
    "\n",
    "        # Add the assistant's response to the conversation history\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": bot_response.strip()})\n",
    "\n",
    "        # print(f\"\\nBot Response: {bot_response.strip()}\")\n",
    "        return bot_response.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    stream_chat_response(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
